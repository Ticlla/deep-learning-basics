# Level 1: Understanding the MNIST Data

> Deep dive into how MNIST data is structured and processed for neural networks.

---

## Table of Contents

1. [Overview](#1-overview)
2. [The MNIST Dataset](#2-the-mnist-dataset)
3. [Image Representation](#3-image-representation)
4. [Data Flow Diagram](#4-data-flow-diagram)
5. [One-Hot Encoding](#5-one-hot-encoding)
6. [Data Augmentation](#6-data-augmentation)
7. [Baseline Classifiers](#7-baseline-classifiers)
8. [Code Reference](#8-code-reference)
9. [Exploration Scripts](#9-exploration-scripts)
10. [Exercises](#10-exercises)

---

## 1. Overview

Before building a neural network, we must understand our data. The MNIST dataset contains handwritten digits that humans labeled. Our goal is to teach a computer to recognize these digits automatically.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE MACHINE LEARNING PIPELINE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   RAW DATA          PREPROCESSING         NEURAL NETWORK        â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚ Image â”‚   â”€â”€â”€â–º  â”‚  Vector   â”‚   â”€â”€â”€â–º  â”‚  Predict  â”‚         â”‚
â”‚   â”‚ 28Ã—28 â”‚         â”‚  (784,1)  â”‚         â”‚   0-9     â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚   â”‚ Label â”‚   â”€â”€â”€â–º  â”‚  One-Hot  â”‚   (used for training)         â”‚
â”‚   â”‚  "5"  â”‚         â”‚  (10,1)   â”‚                               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. The MNIST Dataset

### 2.1 What is MNIST?

**MNIST** = Modified National Institute of Standards and Technology

It's a collection of 70,000 grayscale images of handwritten digits (0-9), commonly used as a "Hello World" for machine learning.

### 2.2 Dataset Split

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MNIST DATASET (70,000 images)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚           TRAINING SET                      â”‚                 â”‚
â”‚  â”‚              50,000 images                  â”‚                 â”‚
â”‚  â”‚                                             â”‚                 â”‚
â”‚  â”‚  Used to TEACH the neural network           â”‚                 â”‚
â”‚  â”‚  The network sees these many times          â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  VALIDATION SET   â”‚  â”‚    TEST SET       â”‚                   â”‚
â”‚  â”‚   10,000 images   â”‚  â”‚   10,000 images   â”‚                   â”‚
â”‚  â”‚                   â”‚  â”‚                   â”‚                   â”‚
â”‚  â”‚  Tune parameters  â”‚  â”‚  Final evaluation â”‚                   â”‚
â”‚  â”‚  (learning rate,  â”‚  â”‚  (never used for  â”‚                   â”‚
â”‚  â”‚   architecture)   â”‚  â”‚   training!)      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Why Three Sets?

| Set | Purpose | Analogy |
|-----|---------|---------|
| **Training** | Learn patterns | Studying textbook examples |
| **Validation** | Tune hyperparameters | Practice tests |
| **Test** | Final evaluation | Final exam (only once!) |

---

## 3. Image Representation

### 3.1 Original Image Format

Each MNIST image is a 28Ã—28 pixel grayscale image:

```
                    28 pixels wide
            â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
          â”Œâ”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”  â–²
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â–ˆâ”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â–ˆâ”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚  28 pixels
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚  tall
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â–ˆâ”€â–ˆâ”€â–ˆâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â”œâ”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¼â”€â”¤  â”‚
          â””â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”˜  â–¼

          Example: Digit "5" (simplified)
          
          Pixel values:
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  0.0 = white (background)    â”‚
          â”‚  1.0 = black (ink)           â”‚
          â”‚  0.5 = gray (edge/gradient)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Flattening: 2D â†’ 1D Vector

Neural networks work with 1D vectors, so we "flatten" the 2D image:

```
    2D IMAGE (28Ã—28)                    1D VECTOR (784Ã—1)
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”
    â”‚ pâ‚€  pâ‚  pâ‚‚ ... â”‚                 â”‚pâ‚€ â”‚ â† pixel 0
    â”‚ pâ‚‚â‚ˆ pâ‚‚â‚‰ pâ‚ƒâ‚€...â”‚     â•â•â•â•â•â•â•â–º    â”‚pâ‚ â”‚ â† pixel 1
    â”‚ pâ‚…â‚† pâ‚…â‚‡ pâ‚…â‚ˆ...â”‚    FLATTEN      â”‚pâ‚‚ â”‚ â† pixel 2
    â”‚ ...            â”‚                 â”‚...â”‚
    â”‚ ...       pâ‚‡â‚ˆâ‚ƒâ”‚                 â”‚pâ‚‡â‚ˆâ‚ƒâ”‚â† pixel 783
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”˜
    
    Total: 28 Ã— 28 = 784 pixels
```

### 3.3 Row-Major Flattening

The flattening reads pixels row by row (row-major order):

```
    Image Grid:                    Flattened Vector:
    
    Row 0:  [ 0,  1,  2, ..., 27]     positions 0-27
    Row 1:  [28, 29, 30, ..., 55]  â†’  positions 28-55
    Row 2:  [56, 57, 58, ..., 83]     positions 56-83
    ...
    Row 27: [756, 757, ..., 783]      positions 756-783
    
    
    Position formula: position = row Ã— 28 + column
    
    Example: pixel at row=10, col=5
             position = 10 Ã— 28 + 5 = 285
```

### 3.4 Why Column Vector (784, 1)?

We use shape `(784, 1)` instead of `(784,)` for matrix multiplication:

```
    NEURAL NETWORK COMPUTATION
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Input layer â†’ Hidden layer:
    
         W          Ã—        x        +      b       =      z
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”       â”Œâ”€â”€â”€â”       â”Œâ”€â”€â”€â”
    â”‚         â”‚       â”‚   â”‚       â”‚   â”‚       â”‚   â”‚
    â”‚  30Ã—784 â”‚   Ã—   â”‚784â”‚   +   â”‚30 â”‚   =   â”‚30 â”‚
    â”‚         â”‚       â”‚Ã—1 â”‚       â”‚Ã—1 â”‚       â”‚Ã—1 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”˜       â””â”€â”€â”€â”˜       â””â”€â”€â”€â”˜
    
    Weights      Input     Bias      Pre-activation
    (30,784)    (784,1)   (30,1)       (30,1)
    
    
    If x were (784,) instead of (784,1):
    âœ— W @ x would give shape (30,) - loses structure
    âœ“ W @ x with (784,1) gives (30,1) - maintains column vector
```

---

## 4. Data Flow Diagram

### 4.1 Complete Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA LOADING PIPELINE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    mnist.pkl.gz
         â”‚
         â”‚  gzip.open() + pickle.load()
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         load_data()                                      â”‚
â”‚                                                                          â”‚
â”‚   Returns: (training_data, validation_data, test_data)                   â”‚
â”‚                                                                          â”‚
â”‚   training_data = (images, labels)                                       â”‚
â”‚                    â”‚        â”‚                                            â”‚
â”‚                    â–¼        â–¼                                            â”‚
â”‚              (50000,784) (50000,)                                        â”‚
â”‚              numpy array  numpy array                                    â”‚
â”‚              float32      int64                                          â”‚
â”‚                                                                          â”‚
â”‚   Example:                                                               â”‚
â”‚   images[0] = [0.0, 0.0, 0.1, ..., 0.9, 0.0]  (784 values)              â”‚
â”‚   labels[0] = 5                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Reshape + One-hot encode
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      load_data_wrapper()                                 â”‚
â”‚                                                                          â”‚
â”‚   Returns: (training_data, validation_data, test_data)                   â”‚
â”‚                                                                          â”‚
â”‚   training_data = [(xâ‚€, yâ‚€), (xâ‚, yâ‚), ..., (xâ‚„â‚‰â‚‰â‚‰â‚‰, yâ‚„â‚‰â‚‰â‚‰â‚‰)]          â”‚
â”‚                                                                          â”‚
â”‚   Each (x, y) pair:                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚                                                                 â”‚    â”‚
â”‚   â”‚   x = image as (784, 1) column vector                          â”‚    â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”                                                   â”‚    â”‚
â”‚   â”‚       â”‚0.000â”‚                                                   â”‚    â”‚
â”‚   â”‚       â”‚0.000â”‚                                                   â”‚    â”‚
â”‚   â”‚       â”‚0.153â”‚  â† actual pixel values                           â”‚    â”‚
â”‚   â”‚       â”‚ ... â”‚                                                   â”‚    â”‚
â”‚   â”‚       â”‚0.992â”‚                                                   â”‚    â”‚
â”‚   â”‚       â”‚0.000â”‚                                                   â”‚    â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”˜                                                   â”‚    â”‚
â”‚   â”‚       (784, 1)                                                  â”‚    â”‚
â”‚   â”‚                                                                 â”‚    â”‚
â”‚   â”‚   y = label as (10, 1) one-hot vector                          â”‚    â”‚
â”‚   â”‚       â”Œâ”€â”€â”€â”€â”€â”                                                   â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 0                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 1                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 2                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 3                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 4                                        â”‚    â”‚
â”‚   â”‚       â”‚  1  â”‚ â† digit 5  â˜… THIS IS THE ANSWER                  â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 6                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 7                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 8                                        â”‚    â”‚
â”‚   â”‚       â”‚  0  â”‚ â† digit 9                                        â”‚    â”‚
â”‚   â”‚       â””â”€â”€â”€â”€â”€â”˜                                                   â”‚    â”‚
â”‚   â”‚       (10, 1)                                                   â”‚    â”‚
â”‚   â”‚                                                                 â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â”‚   NOTE: validation_data and test_data keep labels as integers!           â”‚
â”‚         (easier for accuracy calculation)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Memory Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MEMORY STRUCTURE                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    load_data() output:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    training_data[0] (images):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Image 0    Image 1    Image 2         Image 49999      â”‚
    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚ â”‚  784  â”‚  â”‚  784  â”‚  â”‚  784  â”‚  ...  â”‚  784  â”‚        â”‚
    â”‚ â”‚ floatsâ”‚  â”‚ floatsâ”‚  â”‚ floatsâ”‚       â”‚ floatsâ”‚        â”‚
    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Shape: (50000, 784)  â†’  50,000 rows Ã— 784 columns
    Memory: 50,000 Ã— 784 Ã— 4 bytes = ~157 MB
    
    
    training_data[1] (labels):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  [5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, ...]    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Shape: (50000,)  â†’  50,000 integers
    

    load_data_wrapper() output:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    training_data (list of tuples):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                          â”‚
    â”‚  Index 0:  (xâ‚€, yâ‚€)  where xâ‚€.shape=(784,1), yâ‚€.shape=(10,1)
    â”‚  Index 1:  (xâ‚, yâ‚)  where xâ‚.shape=(784,1), yâ‚.shape=(10,1)
    â”‚  Index 2:  (xâ‚‚, yâ‚‚)  ...                                 â”‚
    â”‚  ...                                                     â”‚
    â”‚  Index 49999: (xâ‚„â‚‰â‚‰â‚‰â‚‰, yâ‚„â‚‰â‚‰â‚‰â‚‰)                          â”‚
    â”‚                                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Length: 50,000 tuples
```

---

## 5. One-Hot Encoding

### 5.1 What is One-Hot Encoding?

One-hot encoding converts a categorical value (like digit 0-9) into a binary vector where only one element is "hot" (set to 1).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ONE-HOT ENCODING                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Integer Label          One-Hot Vector (10,1)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
         0         â†’       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
         1         â†’       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
         2         â†’       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]
         3         â†’       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
         4         â†’       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
         5         â†’       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
         6         â†’       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]
         7         â†’       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
         8         â†’       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]
         9         â†’       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
                           â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘  â†‘
                           0  1  2  3  4  5  6  7  8  9
                              position = digit value
```

### 5.2 Why Use One-Hot Encoding?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WHY ONE-HOT? (Neural Network Output)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Neural Network has 10 output neurons:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                        â”‚
    â”‚  Output Layer (10 neurons)                            â”‚
    â”‚                                                        â”‚
    â”‚  Neuron 0:  â”€â”€â”€â–º  0.02  (probability it's digit 0)    â”‚
    â”‚  Neuron 1:  â”€â”€â”€â–º  0.01  (probability it's digit 1)    â”‚
    â”‚  Neuron 2:  â”€â”€â”€â–º  0.05  (probability it's digit 2)    â”‚
    â”‚  Neuron 3:  â”€â”€â”€â–º  0.03  (probability it's digit 3)    â”‚
    â”‚  Neuron 4:  â”€â”€â”€â–º  0.01  (probability it's digit 4)    â”‚
    â”‚  Neuron 5:  â”€â”€â”€â–º  0.82  (probability it's digit 5) â˜…  â”‚
    â”‚  Neuron 6:  â”€â”€â”€â–º  0.02  (probability it's digit 6)    â”‚
    â”‚  Neuron 7:  â”€â”€â”€â–º  0.02  (probability it's digit 7)    â”‚
    â”‚  Neuron 8:  â”€â”€â”€â–º  0.01  (probability it's digit 8)    â”‚
    â”‚  Neuron 9:  â”€â”€â”€â–º  0.01  (probability it's digit 9)    â”‚
    â”‚                                                        â”‚
    â”‚  Network prediction: argmax([...]) = 5                â”‚
    â”‚                                                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    
    TRAINING: Compare output with target
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Network Output (a):        Target (y):           Error:
    â”Œâ”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚ 0.02 â”‚                   â”‚  0   â”‚              â”‚ 0.02 â”‚
    â”‚ 0.01 â”‚                   â”‚  0   â”‚              â”‚ 0.01 â”‚
    â”‚ 0.05 â”‚                   â”‚  0   â”‚              â”‚ 0.05 â”‚
    â”‚ 0.03 â”‚                   â”‚  0   â”‚              â”‚ 0.03 â”‚
    â”‚ 0.01 â”‚         -         â”‚  0   â”‚      =       â”‚ 0.01 â”‚
    â”‚ 0.82 â”‚                   â”‚  1   â”‚              â”‚-0.18 â”‚ â† should be 1!
    â”‚ 0.02 â”‚                   â”‚  0   â”‚              â”‚ 0.02 â”‚
    â”‚ 0.02 â”‚                   â”‚  0   â”‚              â”‚ 0.02 â”‚
    â”‚ 0.01 â”‚                   â”‚  0   â”‚              â”‚ 0.01 â”‚
    â”‚ 0.01 â”‚                   â”‚  0   â”‚              â”‚ 0.01 â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”˜
    
    The error tells us: "neuron 5 should output higher value"
```

### 5.3 Alternative: Why Not Just Use Integer Labels?

```
    Problem with integer labels:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    If we used single-neuron output with integer target:
    
    Output: 4.7    Target: 5    Error: 0.3
    
    But this implies:
    â€¢ Digit 4 is "close" to digit 5 â† WRONG!
    â€¢ Digit 0 is "far" from digit 9 â† MEANINGLESS!
    
    Digits are CATEGORICAL, not numerical!
    The number 4 is not "more similar" to 5 than to 9.
    
    
    One-hot encoding solves this:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Each digit is equally different from every other digit.
    There's no implicit ordering or distance between classes.
```

---

## 6. Data Augmentation

Data augmentation creates MORE training examples from existing ones, helping the network generalize better.

### 6.1 Common Techniques for MNIST

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA AUGMENTATION TECHNIQUES                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Original Image          Augmented Versions
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•          â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           â”‚           â”‚     â†‘     â”‚  â”‚     â†“     â”‚
    â”‚     5     â”‚    â”€â”€â”€â–º   â”‚     5     â”‚  â”‚     5     â”‚
    â”‚           â”‚           â”‚  Shift Up â”‚  â”‚Shift Down â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  â†  5     â”‚  â”‚     5  â†’  â”‚
                            â”‚Shift Left â”‚  â”‚Shift Rightâ”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    1 image â†’ 5 images (original + 4 shifts)
    50,000 â†’ 250,000 training examples!
```

### 6.2 Impact

| Dataset | Training Images | Test Accuracy |
|---------|-----------------|---------------|
| Original | 50,000 | ~97% |
| Augmented | 250,000 | ~97.5% |

The file `expand_mnist.py` creates the augmented dataset:
```bash
python src/expand_mnist.py
# Creates: data/mnist_expanded.pkl.gz
```

---

## 7. Baseline Classifiers

Before neural networks, how would you classify digits?

### 7.1 Baseline 1: Average Darkness

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DARKNESS-BASED CLASSIFIER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   Idea: Classify by how much "ink" (dark pixels) the digit has          â”‚
â”‚                                                                          â”‚
â”‚   Digit 0: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.173 (lots of ink - circular)              â”‚
â”‚   Digit 8: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.171 (lots of ink - two loops)             â”‚
â”‚   Digit 4: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     0.126 (medium ink)                          â”‚
â”‚   Digit 7: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       0.105 (medium ink)                          â”‚
â”‚   Digit 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.076 (little ink - just a line)            â”‚
â”‚                                                                          â”‚
â”‚   Problem: Many digits have similar darkness!                            â”‚
â”‚   Accuracy: ~22% (barely better than random 10%)                         â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Baseline 2: Support Vector Machine (SVM)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SVM CLASSIFIER                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   Idea: Find hyperplanes that separate classes in 784D space            â”‚
â”‚                                                                          â”‚
â”‚   Uses scikit-learn's SVC with RBF kernel                               â”‚
â”‚   Treats each pixel as a feature (784 features)                          â”‚
â”‚                                                                          â”‚
â”‚   Accuracy: ~98.5% (very good! but slower to train)                     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.3 Comparison

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    ACCURACY COMPARISON                              â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                     â”‚
    â”‚   Random guessing:          10% â–ˆâ–ˆâ–ˆâ–ˆ                               â”‚
    â”‚   Darkness-based:           22% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                           â”‚
    â”‚   Neural Net [784,30,10]:   95% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
    â”‚   Neural Net [784,100,10]:  97% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â”‚   SVM (RBF kernel):       98.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â”‚   CNN (network3.py):       99%+ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
    â”‚                                                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Code Reference

### 8.1 mnist_loader.py Functions

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCTION: load_data()
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 
# Purpose: Load raw MNIST data from pickle file
# Returns: Tuple of 3 tuples: (training, validation, test)
#          Each contains (images_array, labels_array)
#
# Example:
#     training_data, validation_data, test_data = load_data()
#     images = training_data[0]  # shape: (50000, 784)
#     labels = training_data[1]  # shape: (50000,)

def load_data():
    f = gzip.open('../data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')
    f.close()
    return (training_data, validation_data, test_data)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCTION: load_data_wrapper()
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Purpose: Format data for neural network training
# Returns: Tuple of 3 lists
#          - training_data: list of (x, y) where x=(784,1), y=(10,1) one-hot
#          - validation_data: list of (x, y) where x=(784,1), y=integer
#          - test_data: list of (x, y) where x=(784,1), y=integer
#
# Example:
#     training_data, val_data, test_data = load_data_wrapper()
#     x, y = training_data[0]
#     print(x.shape)  # (784, 1)
#     print(y.shape)  # (10, 1)

def load_data_wrapper():
    tr_d, va_d, te_d = load_data()
    
    # Reshape images to column vectors (784, 1)
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    
    # Convert labels to one-hot vectors (10, 1)
    training_results = [vectorized_result(y) for y in tr_d[1]]
    
    # Zip into list of tuples
    training_data = list(zip(training_inputs, training_results))
    
    # Validation & test: reshape images but keep integer labels
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = list(zip(validation_inputs, va_d[1]))
    
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = list(zip(test_inputs, te_d[1]))
    
    return (training_data, validation_data, test_data)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCTION: vectorized_result(j)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# Purpose: Convert integer label to one-hot encoded vector
# Input:   j - integer from 0 to 9
# Returns: numpy array of shape (10, 1) with 1.0 at position j
#
# Example:
#     vectorized_result(3)
#     # Returns: [[0], [0], [0], [1], [0], [0], [0], [0], [0], [0]]

def vectorized_result(j):
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e
```

### 8.2 Usage Example

```python
import mnist_loader

# Load data
training_data, validation_data, test_data = mnist_loader.load_data_wrapper()

# Examine first training example
x, y = training_data[0]

print(f"Image shape: {x.shape}")      # (784, 1)
print(f"Label shape: {y.shape}")      # (10, 1)
print(f"Digit: {y.argmax()}")         # The actual digit (0-9)

# Reshape to visualize
image = x.reshape(28, 28)

# Display with matplotlib
import matplotlib.pyplot as plt
plt.imshow(image, cmap='gray')
plt.title(f"Digit: {y.argmax()}")
plt.show()
```

---

## 9. Exploration Scripts

Run these scripts from the project root to explore the concepts hands-on:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LEVEL 1 EXPLORATION SCRIPTS                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    src/level1/
    â”œâ”€â”€ 1_explore_mnist.py      # Basic data exploration
    â”‚   â””â”€â”€ Topics: Data structure, shapes, one-hot encoding
    â”‚   â””â”€â”€ Run: python src/level1/1_explore_mnist.py
    â”‚
    â”œâ”€â”€ 2_read_all_images.py    # Reading all 50,000 images
    â”‚   â””â”€â”€ Topics: 5 methods to access images (numpy, batches, generators)
    â”‚   â””â”€â”€ Run: python src/level1/2_read_all_images.py
    â”‚
    â”œâ”€â”€ 3_visualize_all.py      # Visualize entire dataset
    â”‚   â””â”€â”€ Topics: Mega-grid, average digits, statistics
    â”‚   â””â”€â”€ Run: python src/level1/3_visualize_all.py
    â”‚
    â”œâ”€â”€ 4_advanced_topics.py    # Column vectors, augmentation, baselines
    â”‚   â””â”€â”€ Topics: Why (784,1)?, data augmentation, SVM baseline
    â”‚   â””â”€â”€ Run: python src/level1/4_advanced_topics.py
    â”‚
    â””â”€â”€ 5_exercises.py          # Hands-on coding exercises
        â””â”€â”€ Topics: Count digits, find images, similarity, pixel importance
        â””â”€â”€ Run: python src/level1/5_exercises.py
```

### Script Output

All scripts save visualizations to timestamped folders:
```
pictures/level1/YYYYMMDD_HHMMSS/
â”œâ”€â”€ 1_sample_digits.png
â”œâ”€â”€ 2_single_digit_analysis.png
â”œâ”€â”€ 3_digit_variations.png
â””â”€â”€ ...
```

---

## 10. Exercises

> ğŸ’¡ **Tip**: Run `python src/level1/5_exercises.py` for interactive exercises with solutions!

### 10.1 Exercise: Data Exploration

```python
# Load the data and answer these questions:
# 1. What is the first label in the training set?
# 2. What is the average pixel value across all training images?
# 3. How many images of digit "7" are in the training set?
```

### 10.2 Exercise: Manual One-Hot Encoding

```python
# Implement your own one-hot encoding function without looking at the original:
def my_one_hot(digit):
    # Your code here
    pass

# Test it:
assert my_one_hot(0).tolist() == [[1],[0],[0],[0],[0],[0],[0],[0],[0],[0]]
assert my_one_hot(5).tolist() == [[0],[0],[0],[0],[0],[1],[0],[0],[0],[0]]
```

### 10.3 Exercise: Reverse Engineering

```python
# Given a one-hot vector, return the digit:
def decode_one_hot(vector):
    # Your code here
    pass

# Test it:
import numpy as np
v = np.array([[0],[0],[0],[1],[0],[0],[0],[0],[0],[0]])
assert decode_one_hot(v) == 3
```

### 10.4 Exercise: Visualization Challenge

```python
# Create a 10x10 grid showing the "average" digit for each class (0-9)
# Average all images of each digit to see what the "typical" digit looks like
```

---

## Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LEVEL 1 KEY TAKEAWAYS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    âœ“ MNIST: 70,000 images of handwritten digits (0-9)
    
    âœ“ Image representation:
      â€¢ Original: 28Ã—28 pixels (2D)
      â€¢ Neural network input: (784, 1) column vector
      â€¢ Pixel values: 0.0 (white) to 1.0 (black)
    
    âœ“ Label representation:
      â€¢ Original: integer 0-9
      â€¢ Neural network target: (10, 1) one-hot vector
    
    âœ“ Two loader functions:
      â€¢ load_data(): raw numpy arrays
      â€¢ load_data_wrapper(): formatted for neural networks
    
    âœ“ Why column vectors (784, 1)?
      â†’ Enables matrix multiplication: W @ x + b
    
    âœ“ Why one-hot encoding?
      â†’ Matches neural network output layer (10 neurons)
      â†’ No implicit ordering between digits
      â†’ Enables direct error calculation
    
    âœ“ Data augmentation:
      â†’ Shifts create 5x more training data (250,000 images)
      â†’ Improves generalization
    
    âœ“ Baselines for comparison:
      â†’ Darkness-based: ~22%
      â†’ SVM: ~98.5%
      â†’ Neural networks: 95-99%+

    
    EXPLORATION SCRIPTS:
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    python src/level1/1_explore_mnist.py      # Start here!
    python src/level1/2_read_all_images.py
    python src/level1/3_visualize_all.py
    python src/level1/4_advanced_topics.py
    python src/level1/5_exercises.py
    
    
    NEXT: Level 2 - Build your first neural network!
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    python src/level2/1_neural_network.py
```

---

*Documentation for Level 1 of Neural Networks and Deep Learning*

